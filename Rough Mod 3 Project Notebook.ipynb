{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, you're going to select a dataset of your choosing and create a classification model. You'll start by identifying a problem you can solve with classification, and then identify a dataset. You'll then use everything you've learned about Data Science and Machine Learning thus far to source a dataset, preprocess and explore it, and then build and interpret a classification model that answers your chosen question.\n",
    "\n",
    "steps\n",
    "1. import libraries/packages\n",
    "2. import data\n",
    "3. inspect data\n",
    "4. clean data \n",
    "4a. do I need to convert lat/long to location? \n",
    "        if no, drop lat, long and is_geocoding_exact\n",
    "5. standardize? \n",
    "6. scaling/transformation\n",
    "7. normalize? \n",
    "8. test/train split and random state\n",
    "9. vanilla tree\n",
    "9A. feature importance \n",
    "10. model performance and accuracy\n",
    "grid search\n",
    "examine best param\n",
    "11. random forests\n",
    "bagged trees \n",
    "\n",
    "pipelines\n",
    "\n",
    "need dummies\n",
    "    pd.get_dummies\n",
    "create armed or no variable? \n",
    "dummies for whole dataset or just bool expressions? \n",
    "group by states "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/cphalpert/census-regions\n",
    "https://github.com/washingtonpost/data-police-shootings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Necessary Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor  \n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix as CM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import chisquare\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if i decide to come back and map coordinates \n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import plotly_express as px\n",
    "import tqdm\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Importing Datasets, Merging, and Inspecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fatal-police-shootings-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing State Classification Dataset to Minimize Classification Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = pd.read_csv('us census bureau regions and divisions.csv')\n",
    "states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = states.drop(['State'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = states.rename(columns={\"State Code\": \"state\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(states, df, on='state')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropping name and id column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['name', 'id', 'state', 'region'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting bool to int \n",
    "dropping geocoding rows with inaccurate lat/long info "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cleaning and Converting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.is_geocoding_exact != 'False']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.applymap(lambda x: 1 if x == True else x)\n",
    "data = data.applymap(lambda x: 0 if x == False else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropping nan values and filling others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['age', 'longitude', 'latitude', 'flee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {'race': 'U', 'armed': 'undetermined'}\n",
    "data = data.fillna(value=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['threat_level'].unique()\n",
    "data['flee'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['manner_of_death'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create new armed column? armed with lethal weapon - true/false? or unarmed v. armed? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['armed'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3A. Examining Armed Values Prior to Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_me = data['armed'].value_counts().reset_index()\n",
    "pie_me.columns = ['armed', 'count']\n",
    "\n",
    "fig = px.pie(\n",
    "    pie_me, \n",
    "    values='count', \n",
    "    names='armed',  \n",
    "    title='Weapon distribution', \n",
    "    width=600, \n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting armed values with a count of less than 59 into 'other'\n",
    "data[['armed']] = data[['armed']].where(data.apply(lambda x: x.groupby(x).transform('count')>59), 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['armed'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Initial Analysis and EDA 1 of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisquare(data.signs_of_mental_illness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data.armed, data.signs_of_mental_illness, normalize='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data.race, data.body_camera, normalize='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"signs_of_mental_illness\", kind=\"count\", palette=\"ch:.25\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"signs_of_mental_illness\", y=\"flee\", hue=\"gender\", kind=\"point\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y=\"signs_of_mental_illness\", hue=\"threat_level\", kind=\"count\",\n",
    "            palette=\"pastel\", edgecolor=\".6\",\n",
    "            data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating df without state, region, city, long, lat, is geocoding exact, and date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to include or not include lat, long, geocoding? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_locdf = data.drop(['city'], axis=1)\n",
    "no_locdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummydf = pd.get_dummies(no_locdf)\n",
    "dummydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_ls = ['Logistic_Regression', 'Random_Forest', 'Gradient_Boosting', 'K_NN']\n",
    "classifier_dc = {\n",
    "               'Logistic_Regression': LogisticRegression(class_weight='auto'),\n",
    "               'Random_Forest': RandomForestClassifier(n_estimators=50, class_weight='balanced'),\n",
    "               'Gradient_Boosting': GradientBoostingClassifier(max_depth=5),\n",
    "               'K_NN': KNeighborsClassifier(n_neighbors=5, weights='distance'),\n",
    "               }\n",
    "n_trials = 25\n",
    "test_size_rt = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dummydf['signs_of_mental_illness']\n",
    "X = dummydf.drop('signs_of_mental_illness', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "taking too long - how to take a sample of the data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_ls = []\n",
    "for ic, (cl_name, Classifier) in enumerate(classifier_dc.items()):\n",
    "    for trial in range(n_trials):\n",
    "        train_signals, test_signals, train_labels, test_labels = train_test_split(X, y, test_size=test_size_rt, random_state=42)\n",
    "        Classifier.fit(train_signals, train_labels)\n",
    "        pred_labels = Classifier.predict(test_signals)\n",
    "        precision = precision_score(test_labels, pred_labels, average='binary')\n",
    "        score_ls.append([cl_name, precision, 'Precision'])\n",
    "        recall = recall_score(test_labels, pred_labels, average='binary')\n",
    "        score_ls.append([cl_name, recall,'Recall'])\n",
    "        F1 = f1_score(test_labels, pred_labels, average='binary')\n",
    "        score_ls.append([cl_name, F1,'f1 Score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "metrics_df = pd.DataFrame(score_ls, columns=['Classifier','Score','Score_type']) #building a dataframe with various metrics\n",
    "ax = sns.violinplot(x=\"Classifier\", y=\"Score\", hue=\"Score_type\", data=metrics_df, linewidth=2) #producing the boxplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initial decision tree analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = DecisionTreeRegressor(random_state=42)  \n",
    "regressor.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create scatterplot to examine features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE lower with location data omitted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test) \n",
    "\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_cv_score = cross_val_score(dt_clf, X_train, y_train, cv=3)\n",
    "mean_dt_cv_score = np.mean(dt_cv_score)\n",
    "\n",
    "print(f\"Mean Cross Validation Score: {mean_dt_cv_score :.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "depth can lead to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 2, 3, 4, 5, 6],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV\n",
    "dt_grid_search = GridSearchCV(dt_clf, dt_param_grid, cv=3, return_train_score=True)\n",
    "\n",
    "# Fit to the data\n",
    "dt_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean training score\n",
    "dt_gs_training_score = np.mean(dt_grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "# Mean test score\n",
    "dt_gs_testing_score = dt_grid_search.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Training Score: {dt_gs_training_score :.2%}\")\n",
    "print(f\"Mean Test Score: {dt_gs_testing_score :.2%}\")\n",
    "print(\"Best Parameter Combination Found During Grid Search:\")\n",
    "dt_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "mean_rf_cv_score = np.mean(cross_val_score(rf_clf, X_train, y_train, cv=3))\n",
    "\n",
    "print(f\"Mean Cross Validation Score for Random Forest Classifier: {mean_rf_cv_score :.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    'n_estimators': [10, 30, 100],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 2, 6, 10],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [3, 6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_grid_search = GridSearchCV(rf_clf, rf_param_grid, cv=3)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training Accuracy: {rf_grid_search.best_score_ :.2%}\")\n",
    "print(\"\")\n",
    "print(f\"Optimal Parameters: {rf_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_score = dt_grid_search.score(X_test, y_test)\n",
    "rf_score = rf_grid_search.score(X_test, y_test)\n",
    "\n",
    "print('Decision tree grid search: ', dt_score)\n",
    "print('Random forest grid search: ', rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = df['signs_of_mental_illness']\n",
    "#X = df.drop('signs_of_mental_illness', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ddf = pd.get_dummies(df, prefix=['signs_of_mental_illness', 'body_camera', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y=\"flee\", hue=\"signs_of_mental_illness\", kind=\"count\",\n",
    "            palette=\"pastel\", edgecolor=\".6\",\n",
    "            data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='threat_level', y='age', data=df, hue='signs_of_mental_illness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(7, 5))\n",
    "sns.despine(f)\n",
    "sns.distplot(df['age'], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "corr = df.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "sns.heatmap(corr, mask=mask,\n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns, cmap='RdBu', annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
